---
title: "p8105_hw2_zj2358"
author: "Zhezheng Jin"
date: "2023-10-02"
output: github_document
---

## Problem 1

```{r setup, include=FALSE}
library(tidyverse)
library(readxl)
options(warn = -1)
```

data clean of pols_month

```{r}
pols_month = read_csv(file = "pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day"), sep = "-") %>%
  mutate(month = month.name[as.integer(month)],
         president = ifelse(prez_dem == 1, "dem", ifelse(prez_gop == 1, "gop", NA))) %>%
  select(-prez_dem, -prez_gop, -day)

pols_month
```

data clean of snp

```{r}
snp = read_csv(file = "snp.csv") %>%
  janitor::clean_names() %>%
  separate(date, into = c("month", "day", "year"), sep = "/") %>%
  mutate(year = ifelse(year >= 0 & year <= 15, paste("20", year, sep = ""), paste("19", year, sep = ""))) %>%
  mutate(month = month.name[as.integer(month)]) %>%
  arrange(year, month) %>%
  select(year, month, day, everything()) %>%
  select(-day)

snp
```

tidy data unemployment 

```{r}
unemployment = read_csv(file = "unemployment.csv") %>%
  pivot_longer(cols = -Year, names_to = "month", values_to = "unemployment") %>%
  mutate(month = tolower(month)) %>%
  mutate(month = case_when(
    month %in% c("jan", "january") ~ "January",
    month %in% c("feb", "february") ~ "February",
    month %in% c("mar", "march") ~ "March",
    month %in% c("apr", "april") ~ "April",
    month %in% c("may") ~ "May",
    month %in% c("jun", "june") ~ "June",
    month %in% c("jul", "july") ~ "July",
    month %in% c("aug", "august") ~ "August",
    month %in% c("sep", "september") ~ "September",
    month %in% c("oct", "october") ~ "October",
    month %in% c("nov", "november") ~ "November",
    month %in% c("dec", "december") ~ "December",
    TRUE ~ NA_character_
  )) %>%
  select(year=Year, month, unemployment, everything())

unemployment
```

merge datasets

```{r}
merged_data <- inner_join(pols_month, snp, by = c("year", "month"))
unemployment$year <- as.character(unemployment$year)
final_data <- inner_join(merged_data, unemployment, by = c("year", "month"))

final_data
```

The dataset `final_data` comprises three primary sources of data, each contributing unique insights. Firstly, `pols_month` offers political data, containing information about the monthly representation of both Republican and Democratic officials at the levels of governor, senator, and representative. Secondly, `snp` contributes financial data, providing monthly closing values for the S&P stock index, which is often used as a benchmark for stock market performance. Lastly, `unemployment` presents economic data in a wide format, featuring monthly unemployment rates. The merged `final_data` dataset seamlessly combines these sources, resulting in a comprehensive dataset with `r nrow(final_data)` rows and `r ncol(final_data)` columns. The dataset spans from `r  range(pull(final_data, year), na.rm = TRUE)`, encompassing a wide range of historical information. Key variables in the dataset include `r colnames(final_data)`.

## Problem 2

Read and Clean: MTW 

```{r MTW}
mtw_df = read_excel(
  "202207 Trash Wheel Collection Data.xlsx",
  cell_cols("A:N"),
  sheet = "Mr. Trash Wheel") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(homes_powered_N = weight_tons*500/30,
         wheel_type = c("MT")) %>% 
  relocate(wheel_type,dumpster,year,month) 
mtw_df
```

Read and Clean: PTW

```{r PTW}
ptw_df = read_excel(
  "202207 Trash Wheel Collection Data.xlsx",
  cell_cols("A:M"),
  sheet = "Professor Trash Wheel") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(homes_powered_N = weight_tons*500/30,
         wheel_type = c("PT")) %>% 
  relocate(wheel_type,dumpster,year,month) 
ptw_df
```

Read and Clean: GTW

```{r GTW}
gtw_df = read_excel(
  "202207 Trash Wheel Collection Data.xlsx",
  cell_cols("A:K"),
  sheet = "Gwynnda Trash Wheel") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(homes_powered_N = weight_tons*500/30,
         wheel_type = c("GT")) %>% 
  relocate(wheel_type,dumpster,year,month) 
gtw_df
```

Combine them together

```{r combine}
mtw_df$year <- as.double(mtw_df$year)
combined_df <- bind_rows(mtw_df, ptw_df, gtw_df)
combined_df
```

The dataset `combined_df` comprises data from three trash-collecting entities: Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel. In total, there are `r nrow(combined_df)` observations in the combined dataset, representing various trash collection events. Key variables include trash_weight, which denotes the weight of trash collected during each event, and homes_powered, representing the approximate number of homes powered by the collected trash. The total weight of trash collected by Professor Trash Wheel is `r sum(ptw_df$weight_tons)` tons, and the total number of cigarette butts collected by Gwynnda in July 2021 is `r format(sum(gtw_df$cigarette_butts[3:7]), scientific = F)`.

## Problem 3

Import, clean, and tidy MCI_bsaeline

```{r}
baseline = read_csv(file = "MCI_baseline.csv", skip=1) %>%
  janitor::clean_names() %>%
  mutate(sex = factor(sex, labels = c("Female", "Male")),
         apoe4 = factor(apoe4, labels = c("APOE4 non-carrier", "APOE4 carrier")),
         age_at_onset = as.numeric(age_at_onset)) %>%
  drop_na(age_at_onset)
baseline
```

The import process involves reading the CSV file, cleaning column names, encoding categorical variables, converting data types where necessary, and handling missing data to prepare the dataset for further analysis. There are `r nrow(baseline)` participants were recruited in the dataset, and of these, `r sum(!is.na(baseline$age_at_onset))` developed MCI. The average baseline age is `r round(mean(baseline$current_age, na.rm=TRUE),digits = 0)` years old. There are `r round(sum(baseline$sex == "Female" & baseline$apoe4 == "APOE4 carrier") / sum(baseline$sex == "Female"), digits = 4) * 100`% of women in the study are APOE4 carriers.

Import, clean, and tidy mci_amyloid

```{r}
amyloid <- read_csv("mci_amyloid.csv", skip=1) %>%
  janitor::clean_names() %>%
  mutate_at(vars(baseline, time_2, time_4, time_6, time_8), ~ as.numeric(.))
amyloid
```

The import process for the `amyloid` dataset consists of several key steps. First, the CSV file is read using `read_csv`, and the header row is skipped to ensure data accuracy. Next, the `janitor::clean_names()` function is applied to standardize and clean the column names. Categorical variables are encoded for analysis, and data types are converted as needed. 
There are `r nrow(distinct(amyloid, study_id))` participants were recruited in the dataset. The average baseline time is `r round(mean(amyloid$baseline, na.rm=TRUE),digits = 2)` years.


Identify participants unique to each dataset

```{r}
participants_only_in_baseline <- baseline %>%
  anti_join(amyloid, by = c("id" = "study_id")) %>%
  select(id)

participants_only_in_amyloid <- amyloid %>%
  anti_join(baseline, by = c("study_id" = "id")) %>%
  select(study_id)
```

There are  `r nrow(participants_only_in_baseline)` Participants unique to the baseline dataset, and `r nrow(participants_only_in_amyloid)` Participants unique to the amyloid dataset.


Combine datasets for participants present in both datasets

```{r}
MCI_combined <- baseline %>%
  inner_join(amyloid, by = c("id" = "study_id"))
```

The resulting dataset `MCI_combined` retains participants who appear in both the `baseline` and `amyloid` datasets, and has `r nrow(MCI_combined)` participants and `r ncol(MCI_combined)` variables. The variables include `r colnames(MCI_combined)`.


Export the combined dataset as a CSV

```{r}
write.csv(MCI_combined, "MCI_combined.csv", row.names = FALSE)
```




